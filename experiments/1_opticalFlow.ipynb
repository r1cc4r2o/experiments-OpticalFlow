{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/5/55/Opticfloweg.png)\n",
    "\n",
    "![](data/out_optical_flow-min.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "def opticalFlow(img1, img2, window_size):\n",
    "    \n",
    "    fr2 = img2.copy()\n",
    "\n",
    "    # Convert images to grayscale\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define the motion model\n",
    "    warp_mode = cv2.MOTION_TRANSLATION\n",
    "\n",
    "    # Define 2x3 or 3x3 matrices and initialize the matrix to identity\n",
    "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "        warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "    else:\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "    # Specify the number of iterations\n",
    "    number_of_iterations = 5000\n",
    "\n",
    "    # Specify the threshold of the increment\n",
    "    # in the correlation coefficient between two iterations\n",
    "    termination_eps = 1e-10\n",
    "\n",
    "    # Define termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,\n",
    "                number_of_iterations, termination_eps)\n",
    "\n",
    "    # Run the ECC algorithm. The results are stored in warp_matrix.\n",
    "    (cc, warp_matrix) = cv2.findTransformECC(img1, img2, warp_matrix,\n",
    "                                             warp_mode, criteria)\n",
    "\n",
    "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "        # Use warpPerspective for Homography\n",
    "        img2_aligned = cv2.warpPerspective(img2, warp_matrix,\n",
    "                                           (img1.shape[1], img1.shape[0]),\n",
    "                                             flags=cv2.INTER_LINEAR +   cv2.WARP_INVERSE_MAP)\n",
    "    else:\n",
    "        # Use warpAffine for Translation, Euclidean and Affine\n",
    "        img2_aligned = cv2.warpAffine(img2, warp_matrix,\n",
    "                                      (img1.shape[1], img1.shape[0]),\n",
    "                                        flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP);\n",
    "        \n",
    "    # calculate optical flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(img1, img2_aligned, None, 0.5, 3, window_size, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # calculate magnitude and angle\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    \n",
    "    # initialize the mask\n",
    "    mask = np.zeros((720, 1280, 3))\n",
    "    \n",
    "    # set image hue according to the optical flow direction\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "    \n",
    "    # normalize magnitude\n",
    "    mask[..., 1] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # apply mask tresholding to the image\n",
    "    mask[..., 2] = cv2.threshold(mask[..., 1], 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # convert HSV to RGB\n",
    "    # img2_al = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "i = 0 # counter for saving images\n",
    "\n",
    "out = cv2.VideoWriter('data/output_mask_optical_flow.mp4', cv2.VideoWriter_fourcc(*'MP4V'), 15, (1280, 720))\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture('data/sample.mp4')\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame2 = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # optical flow\n",
    "    img_mask = opticalFlow(frame1, frame2, 15)\n",
    "    \n",
    "    # update frame1\n",
    "    frame1 = frame2\n",
    "    \n",
    "    # wait for key\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    \n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    # shwo frame\n",
    "    cv2.imshow('frame', img_mask)\n",
    "    \n",
    "    # # convert into cv2 image convert to RGB\n",
    "    img_mask = img_mask.clip(0, 1)\n",
    "    img_mask = np.array(img_mask)\n",
    "    \n",
    "    # # save into a video \n",
    "    # out.write(img_mask)\n",
    "    \n",
    "    if i < 10:\n",
    "        plt.imsave('data/hog_images/optical_00' + str(i) + '.png', img_mask)\n",
    "    elif i < 100:\n",
    "        plt.imsave('data/hog_images/optical_0' + str(i) + '.png', img_mask)\n",
    "    elif i < 1000:\n",
    "        plt.imsave('data/hog_images/optical_' + str(i) + '.png', img_mask)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "\n",
    "path = sorted(glob.glob('data/hog_images/*.png'))\n",
    "\n",
    "# merge all the images into a video\n",
    "img_array = []\n",
    "for filename in path:\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "    \n",
    "out = cv2.VideoWriter('data/out_optical_flow.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 10, size)\n",
    "\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.zeros_like(frame1)\n",
    "mask[..., 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load mp4\n",
    "video = cv2.VideoCapture('data/out_optical_flow.mp4')\n",
    "\n",
    "# convert from mp4 to gif\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
